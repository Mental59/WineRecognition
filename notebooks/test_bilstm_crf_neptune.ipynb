{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e2b82f-b192-461c-a8a8-da4f40165fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\papermill\\iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "if r'G:\\PythonProjects\\WineRecognition2' not in sys.path:\n",
    "    sys.path.insert(0, r'G:\\PythonProjects\\WineRecognition2')\n",
    "\n",
    "from nn.utils import generate_tag_to_ix, get_model_confidence, get_model_mean_confidence, CustomDataset\n",
    "from nn.mlflow_utils import log_mlflow_on_test\n",
    "from nn.model import BiLSTM_CRF\n",
    "from data_master import DataGenerator, count_unk_foreach_tag, DataAnalyzer\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import neptune\n",
    "from neptune.types import File\n",
    "\n",
    "from sklearn_crfsuite import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc713e82-edd2-48a5-9155-2561362d746d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/mentalakv/wine-recognition/e/WIN-21\n"
     ]
    }
   ],
   "source": [
    "run = neptune.init_run(\n",
    "    project=\"mentalakv/wine-recognition\",\n",
    "    api_token=os.getenv('NEPTUNE_API_KEY'),\n",
    "    capture_stderr=True,\n",
    "    capture_stdout=True,\n",
    "    capture_traceback=True,\n",
    "    capture_hardware_metrics=True,\n",
    "    dependencies='infer'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97acfe66-e72e-4f08-a194-e0f966036996",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "TRAIN_RUN_ID = 'WIN-17'\n",
    "RUN_NAME = 'Test-100-256'\n",
    "START_TIME = ''\n",
    "OUTPUT_DIR = 'G:/PythonProjects/WineRecognition2/artifacts/test/test'\n",
    "DATA_PATH = r'G:\\PythonProjects\\WineRecognition2\\data\\text\\menu_txt_tagged_fixed_bottlesize.txt'\n",
    "COMPUTE_METRICS = True\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35f138d6-2366-4727-9255-ff17e788eb7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/mentalakv/wine-recognition/e/WIN-17\n"
     ]
    }
   ],
   "source": [
    "train_run = neptune.init_run(with_id=TRAIN_RUN_ID, mode=\"read-only\", api_token=os.getenv('NEPTUNE_API_KEY'), project=\"mentalakv/wine-recognition\")\n",
    "train_run['model_checkpoints/best_model'].download(destination=OUTPUT_DIR)\n",
    "train_run['data/vocab'].download(destination=OUTPUT_DIR)\n",
    "train_run['data/tags'].download(destination=OUTPUT_DIR)\n",
    "train_run_params = train_run['parameters'].fetch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf65bd7-a0c0-4116-8d1a-e89fa3041636",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'train_run_id': TRAIN_RUN_ID,\n",
    "    'data_path': DATA_PATH,\n",
    "    'compute_metrics': COMPUTE_METRICS,\n",
    "    'device': DEVICE\n",
    "}\n",
    "\n",
    "run['run_info'] = {\n",
    "    'name': RUN_NAME,\n",
    "    'output_directory': OUTPUT_DIR,\n",
    "    'start_time': START_TIME\n",
    "}\n",
    "\n",
    "run['train_run_parameters'] = train_run_params\n",
    "run['parameters'] = params\n",
    "run['sys/tags'].add([train_run_params['model_name'], 'test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02a2d554-8ec8-4663-b1d8-10d0e7eb6f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18208"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(OUTPUT_DIR, 'vocab.json'), 'r', encoding='utf-8') as file:\n",
    "    word_to_ix = json.load(file)\n",
    "\n",
    "vocab_size = len(word_to_ix) \n",
    "    \n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ebf3d52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Add_TradeName': 0,\n",
       " 'Add_Brand': 1,\n",
       " 'Add_KeyWordTrue': 2,\n",
       " 'Add_KeyWordFalse': 3,\n",
       " 'Add_GrapeVarieties': 4,\n",
       " 'Add_GeoIndication': 5,\n",
       " 'Add_WineType': 6,\n",
       " 'Add_BottleSize': 7,\n",
       " 'Add_Sweetness': 8,\n",
       " 'Add_WineColor': 9,\n",
       " 'Add_ClosureType': 10,\n",
       " 'Add_Certificate': 11,\n",
       " 'Add_Vintage': 12,\n",
       " 'Add_Price': 13,\n",
       " 'Punctuation': 14,\n",
       " 'Other': 15}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(os.path.join(OUTPUT_DIR, 'tags.json')) as file:\n",
    "    tag_to_ix = json.load(file)\n",
    "    \n",
    "num_tags = len(tag_to_ix)\n",
    "\n",
    "if not COMPUTE_METRICS:\n",
    "    tag_to_ix['UNKNOWN'] = max(tag_to_ix.values()) + 1\n",
    "\n",
    "ix_to_tag = {value: key for key, value in tag_to_ix.items()}\n",
    "tag_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9823680-213b-4100-af23-6bc0d04420b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH, encoding='utf-8') as file:\n",
    "    x_test = DataGenerator.generate_sents2(file.read().split('\\n'))\n",
    "\n",
    "    \n",
    "dataset = CustomDataset(\n",
    "    x_test,\n",
    "    tag_to_ix,\n",
    "    word_to_ix,\n",
    "    case_sensitive=train_run_params['case_sensitive_vocab'],\n",
    "    convert_nums2words=train_run_params['use_num2words']\n",
    ")\n",
    "\n",
    "y_test = [tags for _, tags in dataset.raw_data()]\n",
    "dataloader = DataLoader(dataset, batch_size=2048, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8fe566a8-c271-4f0b-9abf-3fdd6e6b3b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_CRF(\n",
       "  (embedding): Embedding(18208, 64, padding_idx=18173)\n",
       "  (lstm): LSTM(64, 64, batch_first=True, bidirectional=True)\n",
       "  (hidden2tags): Linear(in_features=128, out_features=16, bias=True)\n",
       "  (crf): CRF(num_tags=16)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BiLSTM_CRF(vocab_size, num_tags, train_run_params['embedding_dim'], train_run_params['hidden_dim'], word_to_ix['PAD'])\n",
    "model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, 'best_model.pth')))\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca7b5d44-2e38-4613-9eb5-9e8725887533",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "with torch.no_grad():\n",
    "    for x, tags, mask, _ in dataloader:\n",
    "        x = x.to(DEVICE)\n",
    "        tags = tags.to(DEVICE)\n",
    "        mask = mask.to(DEVICE)\n",
    "        best_tag_seq = model(x, mask)\n",
    "        y_pred.extend(best_tag_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb8614a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tensor = [\n",
    "    torch.tensor(dataset.sentence_to_indices(sentence), dtype=torch.int64) for sentence, _ in dataset.raw_data()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a565b0-fd99-4b0c-b250-c771db0f5b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_foreach_tag = count_unk_foreach_tag(x_tensor, y_test, list(tag_to_ix), dataset.word_to_ix[dataset.unk])\n",
    "\n",
    "unk_foreach_tag_path = os.path.join(OUTPUT_DIR, 'unk_foreach_tag.json')\n",
    "with open(unk_foreach_tag_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(unk_foreach_tag, file)\n",
    "    \n",
    "run['results/unk_foreach_tag'].upload(unk_foreach_tag_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "079b6291",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fc01ad96764dc4951ca65076437d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = get_model_mean_confidence(model, x_tensor, DEVICE, tqdm)\n",
    "run['metrics/confidence'] = conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f94d518b-8226-4e33-a630-4a8f8f4c39a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, pred in enumerate(y_pred):\n",
    "    y_pred[index] = [ix_to_tag[tag] for tag in pred]\n",
    "\n",
    "x_test = [sentence for sentence, _ in dataset.raw_data()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1e8c00a8-aebc-41dc-bced-3b440d6f6501",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1464: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "labels=list(tag_to_ix)\n",
    "\n",
    "run['metrics/f1'] = metrics.flat_f1_score(y_test, y_pred, average='weighted', labels=labels)\n",
    "run['metrics/precision'] = metrics.flat_precision_score(y_test, y_pred, average='weighted', labels=labels)\n",
    "run['metrics/recall'] = metrics.flat_recall_score(y_test, y_pred, average='weighted', labels=labels)\n",
    "run['metrics/accuracy'] = metrics.flat_accuracy_score(y_test, y_pred)\n",
    "\n",
    "flat_class_report_path = os.path.join(OUTPUT_DIR, 'flat-classification-report.txt')\n",
    "with open(flat_class_report_path, 'w', encoding='utf-8') as file:\n",
    "    file.write(metrics.flat_classification_report(y_test, y_pred, labels=labels, digits=3))\n",
    "    \n",
    "run['metrics/flat_classification_report'].upload(flat_class_report_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84063888-b517-40c9-8305-d6f4ea9055b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = os.path.join(OUTPUT_DIR, 'results.txt')\n",
    "with open(results_path, 'w', encoding='utf-8') as file:\n",
    "    for sentence, tags in zip(x_test, y_pred):\n",
    "        f = ['%-20s'] * len(sentence)\n",
    "        file.write(' '.join(f) % tuple(tags) + '\\n')\n",
    "        file.write(' '.join(f) % tuple(sentence) + '\\n')\n",
    "\n",
    "run['results/model_output'].upload(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bd8eddcb-1acf-4b40-8498-05276a1e2db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_METRICS:\n",
    "    test_eval = []\n",
    "    for sentence, true_tags, pred_tags in zip(x_test, y_test, y_pred):\n",
    "        test_eval.append(list(zip(sentence, true_tags, pred_tags)))\n",
    "        \n",
    "    colored_table_path = os.path.join(OUTPUT_DIR, 'colored-table.xlsx')\n",
    "    diagram_path = os.path.join(OUTPUT_DIR, 'diagram.png')\n",
    "\n",
    "    DataAnalyzer.analyze(\n",
    "            test_eval,\n",
    "            keys=labels,\n",
    "            table_save_path=colored_table_path,\n",
    "            diagram_save_path=diagram_path)\n",
    "    \n",
    "    run['results/colored_table'].upload(colored_table_path)\n",
    "    run['results/diagram'].upload(diagram_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1f60a4-05a1-4347-9f0d-f368a04cd645",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "classes = list(ix_to_tag.values())\n",
    "for sentence, tags in zip(x_test, y_pred):\n",
    "    output = [' '.join(word for word, tag in zip(sentence, tags) if tag == cls) for cls in classes]\n",
    "    df.append(output)\n",
    "\n",
    "source_strings = [' '.join(sentence) for sentence in x_test]\n",
    "results_xlsx_path = os.path.join(OUTPUT_DIR, 'results.xlsx')\n",
    "with pd.ExcelWriter(results_xlsx_path, engine='xlsxwriter') as writer:\n",
    "    pd.DataFrame(df, columns=classes).to_excel(writer, sheet_name='results')\n",
    "    pd.DataFrame(source_strings).to_excel(writer, sheet_name='source')\n",
    "\n",
    "run['results/result_xlsx_table'].upload(results_xlsx_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c54c5fa3-95c7-4128-a149-147ed5c1aa64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 5 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 5 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/mentalakv/wine-recognition/e/WIN-21/metadata\n"
     ]
    }
   ],
   "source": [
    "run.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554b52ca-3a01-4e7d-9562-bc9b7d6e86ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine-recognition",
   "language": "python",
   "name": "wine-recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
