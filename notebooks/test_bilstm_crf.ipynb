{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e2b82f-b192-461c-a8a8-da4f40165fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import string\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "if r'G:\\PythonProjects\\WineRecognition2' not in sys.path:\n",
    "    sys.path.insert(0, r'G:\\PythonProjects\\WineRecognition2')\n",
    "\n",
    "from nn.utils import generate_tag_to_ix, get_model_confidence\n",
    "from nn.mlflow_utils import log_mlflow_on_test\n",
    "from data_master import DataGenerator, count_unk_foreach_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97acfe66-e72e-4f08-a194-e0f966036996",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'BiLSTM_CRF'\n",
    "MODEL_PATH = 'G:/PythonProjects/WineRecognition2/artifacts/train/BiLSTM_CRF_10112021_032950/model/data/model.pth'\n",
    "RUN_NAME = 'Test-100-256'\n",
    "START_TIME = ''\n",
    "OUTPUT_DIR = 'G:/PythonProjects/WineRecognition2/artifacts/test/test'\n",
    "DATA_PATH = r'G:\\PythonProjects\\WineRecognition2\\data\\text\\menu_txt.txt'\n",
    "VOCAB_PATH = 'G:/PythonProjects/WineRecognition2/data/vocabs/Words_Halliday_Wine_AU.json'\n",
    "DATAINFO_PATH = 'G:/PythonProjects/WineRecognition2/data_info.json'\n",
    "COMPUTE_METRICS = False\n",
    "CASE_SENSITIVE_VOCAB = True\n",
    "DEVICE = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02a2d554-8ec8-4663-b1d8-10d0e7eb6f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12139"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(VOCAB_PATH, 'r', encoding='utf-8') as file:\n",
    "    word_to_ix = json.load(file)\n",
    "if not CASE_SENSITIVE_VOCAB:\n",
    "    word_to_ix = {word.lower(): index for word, index in word_to_ix.items()}\n",
    "len(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9823680-213b-4100-af23-6bc0d04420b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_PATH, encoding='utf-8') as file:\n",
    "    x_test = DataGenerator.generate_sents2(file.read().split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57cded28-eff2-4b6d-8f2c-34cad2e5421a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([12047,  1612,   222,   124,    11,   222,   124,  6362,  2646,  3152]),\n",
       " tensor([12047,   895,   619,  8847,     4,   222,   124,  6362,  2646, 12138]),\n",
       " tensor([12041,   528,   279,   222,   124,  6362,  2646, 12138]),\n",
       " tensor([12041, 10532,    15,  2913,  1897,  6362,  2646, 12138]),\n",
       " tensor([12047, 10330,    13,   366,  2913,  1897,  6362,  2646,  7593]),\n",
       " tensor([12041, 10180,   531,  3026,    23,  3373,   531,  6362,  6406,  3026,\n",
       "         12138]),\n",
       " tensor([12047,   822,   222,   124,  6398, 12138]),\n",
       " tensor([12041,  6315,  3268,  6582,  6292,   124,  6582, 12138]),\n",
       " tensor([12036, 10342,  6360,  3643,   222,   124,  6582, 12138]),\n",
       " tensor([12036,   528, 10146,  3251,  6292,   124, 12138,  3152]),\n",
       " tensor([12138, 12110, 12138,  6361,  6362, 12138,   221,   124, 12138, 12138]),\n",
       " tensor([10785, 11940,  6369,  6292,   124, 12138,  8090]),\n",
       " tensor([12138, 12110, 12138,  6393,   221,   124, 12138, 12138]),\n",
       " tensor([10903,  1119, 12138,  6293, 12138]),\n",
       " tensor([10170, 12138, 10103,   222,   124,  6319,  3152]),\n",
       " tensor([12138, 12110, 10170,  5887, 10103, 12138, 12138]),\n",
       " tensor([10167, 11940,  6358,  6305,    26, 12138,   543]),\n",
       " tensor([10168,  6586,   811,   740,  6306, 12138, 12138]),\n",
       " tensor([12057,   874,  6701, 10104, 12138,  6422, 12138, 12138,   153, 12138]),\n",
       " tensor([12047, 10204,  6393, 12138,   261,   124, 12116, 12138]),\n",
       " tensor([12057, 10204,  6359,  4847, 12138,   261,   124, 12116, 12138]),\n",
       " tensor([12047, 10204,  6362,  6442, 12138,   261,   124, 12116, 12138]),\n",
       " tensor([12047, 11519,  8164, 12138, 10102, 12116,  6194, 12116, 12138,  2090]),\n",
       " tensor([12047, 10202, 12110,  2165,  6361, 12138,  3081, 12116, 12138]),\n",
       " tensor([12036, 11519,   740, 12138,  6315, 12138, 12116, 12138]),\n",
       " tensor([12036, 10202, 12110,  2165,  6362,  2646, 12138,  3081, 12116, 12138]),\n",
       " tensor([12034,   325,  8723,  6358, 12138,  1756,   124, 12116, 12138]),\n",
       " tensor([12036, 10202, 12110,  2165,  6358, 12138,  3081, 12116, 12138]),\n",
       " tensor([12138,   569,  6359,  4847, 12138, 12138]),\n",
       " tensor([  280,  1930,  6362,  6442, 12138, 12138]),\n",
       " tensor([    3,  1053,   740, 12138, 12138]),\n",
       " tensor([12138,  1930,  6362,  2646, 12138, 12138]),\n",
       " tensor([10129,  1836,  6358, 12138, 12138]),\n",
       " tensor([12138,   569,  6359,  4847, 12138,  2108]),\n",
       " tensor([  280,  1930,  6362,  6442, 12138,  2108]),\n",
       " tensor([    3,  1053,   740, 12138,  2108]),\n",
       " tensor([  280,  1930,  6362,  2646, 12138,  2108]),\n",
       " tensor([10129,  1836,  6358, 12138,  2108]),\n",
       " tensor([12138, 10392,  6376,  6366,  6415, 12117,  3888,   124, 12116, 12138,\n",
       "           740,  2049, 12138,  1887]),\n",
       " tensor([12138, 10152,   740, 12110,  7756,  6363,  6382, 12117,  1592, 12116,\n",
       "          6292,   124, 12116, 12138, 12138,   740,  2049, 12138,  7462]),\n",
       " tensor([12047,  6362,  2646, 12138, 12117,  6293,  2049, 12138,  1482]),\n",
       " tensor([12034,  6362,  2646,    37, 10689,  4517, 12117,  6297, 12116, 12138,\n",
       "          2049, 12138,  9047]),\n",
       " tensor([12035, 10411,     7,     5, 12117,  6292,   124, 12116, 12138,  6358,\n",
       "          2049, 12138,  7462])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = []\n",
    "y_test = []\n",
    "unk = 'UNK' if CASE_SENSITIVE_VOCAB else 'unk'\n",
    "for index, (sentence, tags) in enumerate(x_test):\n",
    "    y_test.append(tags)\n",
    "    if not CASE_SENSITIVE_VOCAB:\n",
    "        sentence = [word.lower() for word in sentence]\n",
    "    x_tensor.append(torch.tensor([word_to_ix[word] if word in word_to_ix else word_to_ix[unk] for word in sentence], dtype=torch.int64))\n",
    "x_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fe566a8-c271-4f0b-9abf-3fdd6e6b3b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_CRF(\n",
       "  (embedding): Embedding(12139, 256, padding_idx=12137)\n",
       "  (lstm): LSTM(256, 64, batch_first=True, bidirectional=True)\n",
       "  (hidden2tags): Linear(in_features=128, out_features=15, bias=True)\n",
       "  (crf): CRF(num_tags=15)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load(MODEL_PATH).to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca7b5d44-2e38-4613-9eb5-9e8725887533",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\torchcrf\\__init__.py:305: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorCompare.cpp:328.)\n",
      "  score = torch.where(mask[i].unsqueeze(1), next_score, score)\n"
     ]
    }
   ],
   "source": [
    "y_pred = []\n",
    "confs = []\n",
    "with torch.no_grad():\n",
    "    for x in x_tensor:\n",
    "        x = x.unsqueeze(0).to(DEVICE)\n",
    "        best_tag_sequence = model(x)\n",
    "        confidence = torch.exp(-model.neg_log_likelihood(x, torch.tensor(best_tag_sequence)))\n",
    "        y_pred.append(best_tag_sequence)\n",
    "        confs.append(confidence.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508338cb-062a-4001-85cb-cbc43191428b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Add_TradeName',\n",
       " 1: 'Add_Brand',\n",
       " 2: 'Add_KeyWordTrue',\n",
       " 3: 'Add_KeyWordFalse',\n",
       " 4: 'Add_GrapeVarieties',\n",
       " 5: 'Add_GeoIndication',\n",
       " 6: 'Add_WineType',\n",
       " 7: 'Add_BottleSize',\n",
       " 8: 'Add_Sweetness',\n",
       " 9: 'Add_WineColor',\n",
       " 10: 'Add_ClosureType',\n",
       " 11: 'Add_Certificate',\n",
       " 12: 'Add_Vintage',\n",
       " 13: 'Add_Price',\n",
       " 14: 'Punctuation',\n",
       " 15: 'Other'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(DATAINFO_PATH) as file:\n",
    "    tag_to_ix = generate_tag_to_ix(json.load(file)['keys']['all'])\n",
    "ix_to_tag = {value: key for key, value in tag_to_ix.items()}\n",
    "ix_to_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd8848e-4e49-4aeb-942e-9c5125abb8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_foreach_tag = count_unk_foreach_tag(x_tensor, y_test, list(tag_to_ix), word_to_ix[unk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f94d518b-8226-4e33-a630-4a8f8f4c39a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, pred in enumerate(y_pred):\n",
    "    y_pred[index] = [ix_to_tag[tag] for tag in pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9170098-8b1c-4eaa-9735-6c7136cb51fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_params = {\n",
    "    'model_name': MODEL_NAME,\n",
    "    'model_path': MODEL_PATH,\n",
    "    'run_name': RUN_NAME,\n",
    "    'start_time': START_TIME,\n",
    "    'output_dir': OUTPUT_DIR,\n",
    "    'data_path': DATA_PATH,\n",
    "    'vocab_path': VOCAB_PATH,\n",
    "    'datainfo_path': DATAINFO_PATH,\n",
    "    'case_sensitive_vocab': CASE_SENSITIVE_VOCAB,\n",
    "    'device': DEVICE,\n",
    "    'models_confidence': np.mean(confs),\n",
    "    'compute_metrics': COMPUTE_METRICS,\n",
    "    'unk_foreach_tag': json.dumps(unk_foreach_tag)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45015e48-02a1-4971-a872-240680f31a2d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_mlflow_on_test(\n",
    "    run_params,\n",
    "    classes=list(ix_to_tag.values()),\n",
    "    x_test=[sentence for sentence, _ in x_test],\n",
    "    y_pred=y_pred,\n",
    "    y_true=y_test\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine-recognition",
   "language": "python",
   "name": "wine-recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
