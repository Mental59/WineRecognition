{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac361e19-30e1-4b8b-bc2b-11cdb1b3abfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_DIR = r'G:\\PythonProjects\\WineRecognition2'\n",
    "TRAIN_DATASET_PATH = r'G:\\PythonProjects\\WineRecognition2\\data\\text\\data_and_menu_gen_samples\\Halliday_WineSearcher_Bruxelles_MenuGenSamples_v5_BottleSize_fixed.txt'\n",
    "TEST_DATASET_PATH = r'G:\\PythonProjects\\WineRecognition2\\data\\text\\menu_txt_tagged_fixed_bottlesize.txt'\n",
    "DATA_INFO_PATH = r'G:\\PythonProjects\\WineRecognition2\\data_info.json'\n",
    "VOCAB_PATH = r'G:\\PythonProjects\\WineRecognition2\\data\\vocabs\\Words_Halliday_WineSearcher_Bruxelles.json'\n",
    "\n",
    "TASK = \"ner\"\n",
    "NUM_EPOCHS=10\n",
    "MODEL_CHECKPOINT = \"distilbert-base-uncased\"\n",
    "BATCH_SIZE = 64\n",
    "TEST_SIZE = 0.2\n",
    "LABEL_ALL_TOKENS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c555ed16-12f9-481d-a232-32d19de2a429",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\papermill\\iorw.py:50: FutureWarning: pyarrow.HadoopFileSystem is deprecated as of 2.0.0, please use pyarrow.fs.HadoopFileSystem instead.\n",
      "  from pyarrow import HadoopFileSystem\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import json\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "from datasets import load_metric\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "import torch\n",
    "if PROJECT_DIR not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_DIR)\n",
    "from nn.utils import CustomDataset, train, plot_losses, generate_tag_to_ix, get_model_confidence\n",
    "from data_master import DataGenerator, count_unk_foreach_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a39f5a72-68c2-4442-886a-ea1c694ad191",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATA_INFO_PATH) as file:\n",
    "    label_list = json.load(file)['keys']['all']\n",
    "    tag_to_ix = generate_tag_to_ix(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc132b78-bf0c-43b0-8d59-701ca5171569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_dataset(train_dataset_path, test_dataset_path, columns = ('tokens', f'{TASK}_tags')):\n",
    "    with open(train_dataset_path, encoding='utf-8') as file:\n",
    "        train_sents = DataGenerator.generate_sents2(file.read().split('\\n'))\n",
    "\n",
    "    with open(test_dataset_path, encoding='utf-8') as file:\n",
    "        test_sents = DataGenerator.generate_sents2(file.read().split('\\n'))\n",
    "        \n",
    "    train_df = pd.DataFrame(train_sents, columns=columns)\n",
    "    test_df = pd.DataFrame(test_sents, columns=columns)\n",
    "    \n",
    "    train_df['whole_string'] = train_df['tokens'].apply(' '.join)\n",
    "    test_df['whole_string'] = test_df['tokens'].apply(' '.join)\n",
    "    \n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "    \n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c112e10-19f3-4171-9888-7f8fd0178917",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n",
    "train_dataset, test_dataset = get_token_dataset(TRAIN_DATASET_PATH, TEST_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f43ca7ef-f015-4ea7-87bd-b64b5a4b68f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_corpus():\n",
    "    for start_idx in range(0, len(train_dataset), 1000):\n",
    "        samples = train_dataset[start_idx : start_idx + 1000]\n",
    "        yield samples[\"whole_string\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1763dbb-6883-4b80-b829-76a85fe357d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tokenizers/distilbert-base-uncased-2023-03-05\\\\tokenizer_config.json',\n",
       " './tokenizers/distilbert-base-uncased-2023-03-05\\\\special_tokens_map.json',\n",
       " './tokenizers/distilbert-base-uncased-2023-03-05\\\\vocab.txt',\n",
       " './tokenizers/distilbert-base-uncased-2023-03-05\\\\added_tokens.json',\n",
       " './tokenizers/distilbert-base-uncased-2023-03-05\\\\tokenizer.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = old_tokenizer.train_new_from_iterator(get_training_corpus(), vocab_size=52000)\n",
    "tokenizer.save_pretrained(f'./tokenizers/{MODEL_CHECKPOINT}-{datetime.today().strftime(\"%Y-%m-%d\")}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f0dc4ed-7add-42b6-a440-004c6b8c63e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"{TASK}_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(tag_to_ix[label[word_idx]])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(tag_to_ix[label[word_idx]] if LABEL_ALL_TOKENS else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03ca82b8-3913-4ff3-a3e3-90e99479d242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/735803 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/49 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(tokenize_and_align_labels, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8828280-5028-4496-a91b-93d0bf59b0da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForTokenClassification: ['vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(MODEL_CHECKPOINT, num_labels=len(tag_to_ix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3425ff-0886-4812-8e52-9a5019a0e5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = MODEL_CHECKPOINT.split(\"/\")[-1]\n",
    "args = TrainingArguments(\n",
    "    f\"{model_name}-finetuned-{TASK}\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    num_train_epochs=NUM_EPOCHS,\n",
    "    weight_decay=0.01,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2a2f81d-755e-4e0c-9a68-68f338a2b232",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d0231e8-da3d-4811-bc52-79df1c5e8591",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mental\\AppData\\Local\\Temp/ipykernel_17600/152412463.py:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"seqeval\")\n"
     ]
    }
   ],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ddf892d4-088a-42b8-83a4-3597ad3a47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5d6bc3f-dc76-4ce0-ba1e-194b79150104",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_train_eval_dataset = tokenized_train_dataset.train_test_split(test_size=TEST_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2380c351-1b51-4ab3-a818-7b90efccb005",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_train_eval_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_train_eval_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cbd4db4-003b-4101-9a89-a83e72f14a1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: whole_string, tokens, ner_tags. If whole_string, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 588642\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 91980\n",
      "  Number of trainable parameters = 66375184\n",
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='56652' max='91980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [56651/91980 47:15 < 29:28, 19.98 it/s, Epoch 6.16/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>0.011717</td>\n",
       "      <td>0.994432</td>\n",
       "      <td>0.994145</td>\n",
       "      <td>0.994288</td>\n",
       "      <td>0.996384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.007705</td>\n",
       "      <td>0.996674</td>\n",
       "      <td>0.996173</td>\n",
       "      <td>0.996423</td>\n",
       "      <td>0.997688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>0.997586</td>\n",
       "      <td>0.997415</td>\n",
       "      <td>0.997501</td>\n",
       "      <td>0.998406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.004526</td>\n",
       "      <td>0.998023</td>\n",
       "      <td>0.997926</td>\n",
       "      <td>0.997975</td>\n",
       "      <td>0.998662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.998173</td>\n",
       "      <td>0.997991</td>\n",
       "      <td>0.998082</td>\n",
       "      <td>0.998677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.998394</td>\n",
       "      <td>0.998196</td>\n",
       "      <td>0.998295</td>\n",
       "      <td>0.998861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.004462</td>\n",
       "      <td>0.998278</td>\n",
       "      <td>0.998185</td>\n",
       "      <td>0.998232</td>\n",
       "      <td>0.998818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-1000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-1000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-1000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-1000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-1000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-1500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-1500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-1500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-1500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-1500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-2000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-2000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-2000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-2000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-2000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-2500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-2500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-2500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-2500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-2500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-3000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-3000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-3000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-3000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-3000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-3500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-3500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-3500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-3500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-3500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-4000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-4000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-4000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-4000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-4000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-4500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-4500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-4500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-4500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-4500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-5000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-5000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-5000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-5000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-5000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-5500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-5500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-5500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-5500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-5500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-6000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-6000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-6000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-6000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-6000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-6500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-6500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-6500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-6500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-6500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-7000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-7000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-7000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-7000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-7000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-7500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-7500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-7500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-7500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-7500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-8000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-8000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-8000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-8000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-8000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-8500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-8500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-8500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-8500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-8500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-9000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-9000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-9000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-9000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-9000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: whole_string, tokens, ner_tags. If whole_string, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 147161\n",
      "  Batch size = 64\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GeoIndication seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Price seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_TradeName seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Brand seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GrapeVarieties seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_ClosureType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_BottleSize seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Sweetness seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Vintage seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Punctuation seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineColor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordTrue seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Other seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Certificate seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordFalse seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-9500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-9500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-9500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-9500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-9500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-10000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-10000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-10000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-10000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-10000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-10500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-10500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-10500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-10500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-10500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-11000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-11000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-11000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-11000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-11000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-11500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-11500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-11500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-11500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-11500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-12000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-12000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-12000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-12000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-12000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-12500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-12500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-12500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-12500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-12500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-13000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-13000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-13000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-13000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-13000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-13500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-13500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-13500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-13500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-13500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-14000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-14000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-14000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-14000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-14000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-14500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-14500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-14500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-14500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-14500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-15000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-15000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-15000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-15000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-15000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-15500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-15500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-15500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-15500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-15500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-16000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-16000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-16000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-16000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-16000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-16500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-16500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-16500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-16500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-16500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-17000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-17000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-17000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-17000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-17000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-17500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-17500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-17500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-17500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-17500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-18000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-18000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-18000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-18000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-18000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: whole_string, tokens, ner_tags. If whole_string, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 147161\n",
      "  Batch size = 64\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GeoIndication seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Price seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_TradeName seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Brand seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GrapeVarieties seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_ClosureType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_BottleSize seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Sweetness seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Vintage seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Punctuation seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineColor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordTrue seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Other seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Certificate seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordFalse seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-18500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-18500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-18500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-18500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-18500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-19000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-19000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-19000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-19000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-19000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-19500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-19500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-19500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-19500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-19500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-20000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-20000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-20000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-20000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-20000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-20500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-20500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-20500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-20500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-20500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-21000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-21000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-21000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-21000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-21000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-21500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-21500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-21500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-21500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-21500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-22000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-22000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-22000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-22000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-22000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-22500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-22500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-22500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-22500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-22500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-23000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-23000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-23000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-23000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-23000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-23500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-23500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-23500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-23500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-23500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-24000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-24000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-24000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-24000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-24000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-24500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-24500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-24500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-24500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-24500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-25000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-25000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-25000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-25000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-25000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-25500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-25500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-25500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-25500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-25500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-26000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-26000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-26000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-26000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-26000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-26500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-26500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-26500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-26500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-26500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-27000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-27000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-27000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-27000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-27000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-27500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-27500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-27500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-27500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-27500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: whole_string, tokens, ner_tags. If whole_string, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 147161\n",
      "  Batch size = 64\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GeoIndication seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Price seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_TradeName seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Brand seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GrapeVarieties seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_ClosureType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_BottleSize seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Sweetness seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Vintage seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Punctuation seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineColor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordTrue seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Other seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Certificate seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordFalse seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-28000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-28000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-28000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-28000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-28000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-28500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-28500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-28500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-28500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-28500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-29000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-29000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-29000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-29000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-29000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-29500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-29500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-29500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-29500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-29500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-30000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-30000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-30000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-30000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-30000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-30500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-30500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-30500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-30500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-30500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-31000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-31000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-31000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-31000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-31000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-31500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-31500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-31500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-31500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-31500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-32000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-32000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-32000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-32000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-32000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-32500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-32500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-32500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-32500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-32500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-33000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-33000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-33000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-33000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-33000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-33500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-33500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-33500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-33500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-33500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-34000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-34000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-34000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-34000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-34000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-34500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-34500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-34500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-34500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-34500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-35000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-35000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-35000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-35000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-35000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-35500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-35500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-35500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-35500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-35500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-36000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-36000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-36000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-36000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-36000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-36500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-36500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-36500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-36500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-36500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: whole_string, tokens, ner_tags. If whole_string, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 147161\n",
      "  Batch size = 64\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GeoIndication seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Price seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_TradeName seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Brand seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GrapeVarieties seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_ClosureType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_BottleSize seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Sweetness seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Vintage seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Punctuation seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineColor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordTrue seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Other seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Certificate seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordFalse seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-37000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-37000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-37000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-37000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-37000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-37500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-37500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-37500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-37500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-37500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-38000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-38000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-38000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-38000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-38000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-38500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-38500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-38500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-38500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-38500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-39000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-39000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-39000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-39000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-39000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-39500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-39500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-39500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-39500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-39500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-40000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-40000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-40000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-40000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-40000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-40500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-40500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-40500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-40500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-40500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-41000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-41000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-41000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-41000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-41000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-41500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-41500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-41500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-41500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-41500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-42000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-42000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-42000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-42000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-42000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-42500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-42500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-42500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-42500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-42500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-43000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-43000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-43000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-43000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-43000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-43500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-43500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-43500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-43500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-43500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-44000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-44000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-44000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-44000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-44000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-44500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-44500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-44500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-44500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-44500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-45000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-45000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-45000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-45000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-45000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-45500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-45500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-45500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-45500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-45500\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: whole_string, tokens, ner_tags. If whole_string, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 147161\n",
      "  Batch size = 64\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GeoIndication seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Price seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_TradeName seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Brand seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GrapeVarieties seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_ClosureType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_BottleSize seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Sweetness seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Vintage seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Punctuation seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineColor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordTrue seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Other seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Certificate seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordFalse seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-46000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-46000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-46000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-46000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-46000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-46500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-46500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-46500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-46500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-46500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-47000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-47000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-47000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-47000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-47000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-47500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-47500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-47500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-47500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-47500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-48000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-48000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-48000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-48000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-48000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-48500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-48500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-48500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-48500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-48500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-49000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-49000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-49000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-49000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-49000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-49500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-49500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-49500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-49500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-49500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-50000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-50000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-50000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-50000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-50000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-50500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-50500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-50500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-50500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-50500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-51000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-51000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-51000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-51000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-51000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-51500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-51500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-51500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-51500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-51500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-52000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-52000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-52000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-52000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-52000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-52500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-52500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-52500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-52500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-52500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-53000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-53000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-53000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-53000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-53000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-53500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-53500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-53500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-53500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-53500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-54000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-54000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-54000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-54000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-54000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-54500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-54500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-54500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-54500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-54500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-55000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-55000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-55000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-55000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-55000\\special_tokens_map.json\n",
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: whole_string, tokens, ner_tags. If whole_string, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 147161\n",
      "  Batch size = 64\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GeoIndication seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Price seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_TradeName seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Brand seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GrapeVarieties seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_ClosureType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_BottleSize seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Sweetness seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Vintage seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Punctuation seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineColor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordTrue seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Other seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Certificate seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordFalse seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-55500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-55500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-55500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-55500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-55500\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-56000\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-56000\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-56000\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-56000\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-56000\\special_tokens_map.json\n",
      "Saving model checkpoint to distilbert-base-uncased-finetuned-ner\\checkpoint-56500\n",
      "Configuration saved in distilbert-base-uncased-finetuned-ner\\checkpoint-56500\\config.json\n",
      "Model weights saved in distilbert-base-uncased-finetuned-ner\\checkpoint-56500\\pytorch_model.bin\n",
      "tokenizer config file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-56500\\tokenizer_config.json\n",
      "Special tokens file saved in distilbert-base-uncased-finetuned-ner\\checkpoint-56500\\special_tokens_map.json\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17600/4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1541\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1542\u001b[0m         )\n\u001b[1;32m-> 1543\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1544\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1545\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1789\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1790\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1791\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1793\u001b[0m                 if (\n",
      "\u001b[1;32mD:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2530\u001b[0m         \"\"\"\n\u001b[0;32m   2531\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2532\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2533\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2534\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_sagemaker_mp_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_prepare_inputs\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2475\u001b[0m         \u001b[0mhandling\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \"\"\"\n\u001b[1;32m-> 2477\u001b[1;33m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2478\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m             raise ValueError(\n",
      "\u001b[1;32mD:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_prepare_input\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   2457\u001b[0m         \"\"\"\n\u001b[0;32m   2458\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2459\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2460\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2461\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2457\u001b[0m         \"\"\"\n\u001b[0;32m   2458\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2459\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2460\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2461\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_prepare_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_prepare_input\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   2467\u001b[0m                 \u001b[1;31m# may need special handling to match the dtypes of the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2468\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhf_deepspeed_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2469\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2470\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62618de9-66a9-47a0-812d-3911c27e8b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the evaluation set don't have a corresponding argument in `DistilBertForTokenClassification.forward` and have been ignored: whole_string, tokens, ner_tags. If whole_string, tokens, ner_tags are not expected by `DistilBertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 147161\n",
      "  Batch size = 64\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GeoIndication seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Price seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_TradeName seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Brand seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_GrapeVarieties seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_ClosureType seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_BottleSize seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Sweetness seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Vintage seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Punctuation seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_WineColor seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordTrue seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Other seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_Certificate seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "D:\\ProgramFiles\\anaconda3\\envs\\wine-recognition\\lib\\site-packages\\seqeval\\metrics\\sequence_labeling.py:171: UserWarning: Add_KeyWordFalse seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.004462342243641615,\n",
       " 'eval_precision': 0.9982782408266464,\n",
       " 'eval_recall': 0.9981850011422628,\n",
       " 'eval_f1': 0.9982316188071947,\n",
       " 'eval_accuracy': 0.9988182253672276}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a416c-1d76-4b2d-a268-476e12542a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(f'{MODEL_CHECKPOINT}-wine')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cba9d80-28f6-4e81-8f65-edb7cd2d1c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f68759-24a6-48d1-947e-8b248ce2e971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine-recognition",
   "language": "python",
   "name": "wine-recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
