{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fea23a7-2917-4c5e-a2c1-e88fc2c3a5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys\n",
    "if not r'G:\\PythonProjects\\WineRecognition2' in sys.path:\n",
    "    sys.path.insert(0, r'G:\\PythonProjects\\WineRecognition2')\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_master import DataGenerator, DataLoader, count_unk_foreach_tag, compute_model_confidence\n",
    "from mlflow_utils import log_mlflow_on_test\n",
    "from features import features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cacb157b-1e14-4ac3-a2fa-7439443c2764",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "MODEL_PATH = r\"G:/PythonProjects/WineRecognition2/artifacts/train/CRF_with_LSTM_and_Our_features_26112021_150906\"\n",
    "DATASET_PATH = r\"G:\\PythonProjects\\WineRecognition2\\data\\text\\menu_txt.txt\"\n",
    "LSTM_MODEL_PATH = r\"G:/PythonProjects/WineRecognition2/artifacts/train/BiLSTM_CRF_24112021_223320/model/data/model.pth\"\n",
    "VOCAB_PATH = r\"G:\\PythonProjects\\WineRecognition2\\data\\vocabs\\Words_Halliday_Wine_AU.json\"\n",
    "CASE_SENSITIVE_VOCAB = False\n",
    "DICTIONARY_PATH = r\"G:\\PythonProjects\\WineRecognition2\\data\\dictionaries\\Dict-byword_Halliday_Winesearcher_Wine_AU-only_completed_rows\"\n",
    "DATAINFO_PATH = 'G:/PythonProjects/WineRecognition2/data_info.json'\n",
    "DO_PREPROCESS = False\n",
    "DEVICE = 'cuda'\n",
    "OUTPUT_DIR = ''\n",
    "START_TIME = ''\n",
    "RUN_NAME = 'test_run'\n",
    "COMPUTE_METRICS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fcdeb62b-7ee6-47b9-89ae-51b109d38310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.68 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with open(os.path.join(MODEL_PATH, 'model', 'model.pkl'), 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "freq_dict = DataLoader.load_frequency_dictionary(DICTIONARY_PATH)\n",
    "bilstm_crf = torch.load(LSTM_MODEL_PATH).to(DEVICE).eval()\n",
    "with open(VOCAB_PATH, 'r', encoding='utf-8') as file:\n",
    "    word_to_ix = json.load(file)\n",
    "if not CASE_SENSITIVE_VOCAB:\n",
    "    word_to_ix = {word.lower(): index for word, index in word_to_ix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "003e5eb4-0779-496c-ae4e-38f487397e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.28 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(43, 43)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# getting features from lstm\n",
    "\n",
    "def get_lstm_features(model, x):\n",
    "    x = model.embedding(x)\n",
    "    x, _ = model.lstm(x)\n",
    "    return x\n",
    "\n",
    "def features_with_keys(sentence):\n",
    "    return [{f'A{i}': feature for i, feature in enumerate(features)} for features in sentence]\n",
    "\n",
    "def is_number(s):\n",
    "    try:\n",
    "        float(s)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def preprocess_sent(x_sent, y_sent):\n",
    "    indices = [i for i, (x, y) in enumerate(zip(x_sent, y_sent)) if y == 'Add_BottleSize' and is_number(x)]\n",
    "    for i in indices:\n",
    "        x_sent[i] = str(float(x_sent[i]))\n",
    "\n",
    "unk = 'UNK' if CASE_SENSITIVE_VOCAB else 'unk'\n",
    "X_tensors = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    sents = DataGenerator.generate_sents2(open(DATASET_PATH, encoding='utf-8').read().split('\\n'))\n",
    "    metadata = {'features': [], 'labels': []}\n",
    "\n",
    "    for x_sent, y_sent in sents:\n",
    "        if DO_PREPROCESS:\n",
    "            preprocess_sent(x_sent, y_sent)\n",
    "        \n",
    "        our_features = features.sent2features(list(zip(x_sent, y_sent)), freq_dict)\n",
    "        \n",
    "        if not CASE_SENSITIVE_VOCAB:\n",
    "            x_sent = [word.lower() for word in x_sent]\n",
    "        \n",
    "        x_tensor = torch.tensor(\n",
    "            [word_to_ix[word] if word in word_to_ix else word_to_ix[unk] for word in x_sent],\n",
    "            dtype=torch.int64\n",
    "        )\n",
    "        X_tensors.append(x_tensor)\n",
    "        \n",
    "        final_features = get_lstm_features(bilstm_crf, x_tensor.to(DEVICE).unsqueeze(0))\n",
    "        final_features = features_with_keys(final_features.squeeze(0).detach().cpu().numpy())\n",
    "        for i in range(len(x_sent)):\n",
    "            final_features[i].update(our_features[i])\n",
    "        metadata['features'].append(final_features)\n",
    "        metadata['labels'].append(y_sent)\n",
    "        \n",
    "y_test = metadata['labels']\n",
    "X_test = metadata['features']\n",
    "len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bd7aa18-66d3-4cd1-a821-260d8e7940c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 44.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = model.predict(X_test)\n",
    "marginals = model.predict_marginals(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60899c98-94ec-47ba-a442-bb7d2f6a69e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(DATAINFO_PATH) as file:\n",
    "    unk_foreach_tag = count_unk_foreach_tag(X_tensors, y_test, json.load(file)['keys']['all'], word_to_ix[unk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1f140f-4ed9-4ad5-bb2a-e2ec731ed9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "confs = compute_model_confidence(marginals)\n",
    "prob_table = DataGenerator.generate_probability_table(marginals, sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c9deada-dc11-44da-8da4-2a0762495667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if COMPUTE_METRICS:\n",
    "    test_eval = [list(zip(sentence, tags, y_pred[index])) for index, (sentence, tags) in enumerate(sents)]  \n",
    "else:\n",
    "    test_eval = []\n",
    "    for i, (sentence, tags) in enumerate(sents):\n",
    "        dct = dict.fromkeys(model.classes_, '')\n",
    "        for j, word in enumerate(sentence):\n",
    "            if y_pred[i][j] in dct.keys():\n",
    "                dct[y_pred[i][j]] += f'{word} '\n",
    "        test_eval.append({key: value.rstrip() for key, value in dct.items()})\n",
    "    test_eval = pd.DataFrame({key: [wine.get(key) for wine in test_eval] for key in model.classes_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b44767e1-eba0-4b29-88d2-5faba40d9628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "run_params = {\n",
    "    'model_path': MODEL_PATH,\n",
    "    'lstm_model_path': LSTM_MODEL_PATH,\n",
    "    'vocab_path': VOCAB_PATH,\n",
    "    'case_sensitive_vocab': CASE_SENSITIVE_VOCAB,\n",
    "    'dictionary_path': DICTIONARY_PATH,\n",
    "    'datainfo_path': DATAINFO_PATH,\n",
    "    'device': DEVICE,\n",
    "    'dataset_path': DATASET_PATH,\n",
    "    'output_dir': OUTPUT_DIR,\n",
    "    'compute_metrics': COMPUTE_METRICS,\n",
    "    'start_time': START_TIME,\n",
    "    'do_preprocess': DO_PREPROCESS,\n",
    "    'runname': RUN_NAME,\n",
    "    'models_confidence': np.mean(confs),\n",
    "    'unk_foreach_tag': json.dumps(unk_foreach_tag),\n",
    "    'prob_table': prob_table\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed0147e-f285-4a63-9828-a5e95abf822a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_mlflow_on_test(\n",
    "    run_params=run_params,\n",
    "    model=model,\n",
    "    y_true=y_test,\n",
    "    y_pred=y_pred,\n",
    "    test_eval=test_eval\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07d8fca-a4af-4123-b5cf-01a6ce3b9ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wine-recognition",
   "language": "python",
   "name": "wine-recognition"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
